{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoTfwF9ksvhuyVScvI05jA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KfoyhSqc-3jn","executionInfo":{"status":"ok","timestamp":1679583806878,"user_tz":-330,"elapsed":5946,"user":{"displayName":"Soutrik Roy","userId":"15339520230730619614"}},"outputId":"42c7c2bf-b95a-4cb3-c3ae-4584289bd701"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.11.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.51.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.31.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (15.0.6.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.11.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.19.6)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tA8kwNBVF2WM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9bEZe4bzF2PF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PV3Ee8O-F1-f","executionInfo":{"status":"ok","timestamp":1679611223330,"user_tz":-330,"elapsed":5381,"user":{"displayName":"Soutrik Roy","userId":"15339520230730619614"}},"outputId":"708e8789-c6b2-4d56-bf34-2aecaf9bfbb0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (2.1.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras) (6.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras) (1.16.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras) (1.22.4)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.9/dist-packages (from keras) (1.10.1)\n"]}]},{"cell_type":"code","source":["!pip install vis"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"92lJQtobGaxu","executionInfo":{"status":"ok","timestamp":1679585582612,"user_tz":-330,"elapsed":6979,"user":{"displayName":"Soutrik Roy","userId":"15339520230730619614"}},"outputId":"272c3549-2487-4a90-baee-7cfc78907356"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting vis\n","  Downloading vis-0.0.5-py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from vis) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from vis) (3.7.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (3.0.9)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (5.12.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (4.39.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (8.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (1.0.7)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->vis) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->vis) (1.16.0)\n","Installing collected packages: vis\n","Successfully installed vis-0.0.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["vis"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install q keras==2.1.5\n","!pip install vis\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iegN28vPHLl0","executionInfo":{"status":"ok","timestamp":1679611215009,"user_tz":-330,"elapsed":11056,"user":{"displayName":"Soutrik Roy","userId":"15339520230730619614"}},"outputId":"a19b52c7-4bc3-4d53-8a55-2f015ed6f96c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting q\n","  Downloading q-2.7-py2.py3-none-any.whl (10 kB)\n","Collecting keras==2.1.5\n","  Downloading Keras-2.1.5-py2.py3-none-any.whl (334 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.9/334.9 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from keras==2.1.5) (6.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.9/dist-packages (from keras==2.1.5) (1.10.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras==2.1.5) (1.22.4)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from keras==2.1.5) (1.16.0)\n","Installing collected packages: q, keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.11.0\n","    Uninstalling keras-2.11.0:\n","      Successfully uninstalled keras-2.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.11.0 requires keras<2.12,>=2.11.0, but you have keras 2.1.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.1.5 q-2.7\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting vis\n","  Downloading vis-0.0.5-py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from vis) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from vis) (3.7.1)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (5.12.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (23.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (4.39.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->vis) (3.0.9)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->vis) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->vis) (1.16.0)\n","Installing collected packages: vis\n","Successfully installed vis-0.0.5\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import copy\n","import numpy as np\n","import matplotlib.image as img\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from PIL import Image\n","from keras import backend as K\n","from keras import optimizers\n","from keras.models import Sequential\n","from keras.callbacks import TensorBoard, Callback\n","from keras.utils import to_categorical as one_hot\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Activation, Dropout, Flatten, Dense\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from keras import optimizers\n","\n","from vis.utils import utils\n","from vis.visualization import visualize_activation, visualize_saliency, get_num_filters\n","\n","model_version = \"v1.6\"\n","emotions = [\"happy\", \"angry\", \"sad\"]\n","w, h = (60, 60)\n","epochs = 50\n","\n","COLOR = {\n","\t'G':'\\x1B[32m',\n","\t'R':'\\x1B[31m',\n","\t'RS':'\\x1B[0m'\n","}\n","\n","# PlotStats callback for printing custom plot stats of the model.\n","class PlotStats(Callback):\n","\tdef on_train_end(self, logs={}):\n","\t\t# model loss plot.\n","\t\tplt.plot(self.losses)\n","\t\tplt.plot(self.val_losses,  color=\"green\")\n","\t\tplt.title('Learning curve for model loss')\n","\t\tplt.ylabel('loss')\n","\t\tplt.xlabel('epochs ({})'.format(epochs))\n","\t\tplt.legend(['training', 'testing'], loc='upper left')\n","\t\tplt.savefig('model_{}_loss.png'.format(model_version))\n","\t\tplt.gcf().clf()\n","\t\t\n","\t\t# model accuracy plot.\n","\t\tplt.plot(self.acc)\n","\t\tplt.plot(self.val_acc,  color=\"green\")\n","\t\tplt.title('Learning curve for model accuracy'.format(epochs))\n","\t\tplt.ylabel('accuracy')\n","\t\tplt.xlabel('epochs ({})'.format(epochs))\n","\t\tplt.legend(['training', 'testing'], loc='upper left')\n","\t\tplt.savefig('model_{}_accuracy.png'.format(model_version))\n","\t\tplt.gcf().clf()\n","\t\t\n","\tdef on_train_begin(self, logs={}):\n","\t\tself.losses = []\n","\t\tself.acc = []\n","\t\tself.val_acc = []\n","\t\tself.val_losses = []\n","\n","\tdef on_epoch_end(self, batch, logs={}):\n","\t\tself.losses.append(logs.get('loss'))\n","\t\tself.val_losses.append(logs.get('val_loss'))\t\t\n","\t\tself.acc.append(logs.get('acc'))\n","\t\tself.val_acc.append(logs.get('val_acc'))\n","\n","# loads the emotion datasets and constructs them into numpy arrays \n","# for training & testing for a character.\n","def load_emotion_data_for(character):\n","\tDATASETS = {\n","\t\t'happy': {\n","\t\t\t'training':'datasets/' + character + '/happy/training',\n","\t\t\t'testing':'datasets/'  + character + '/happy/testing',\n","\t\t},\n","\t\t'angry': {\n","\t\t\t'training':'datasets/' + character + '/angry/training',\n","\t\t\t'testing':'datasets/'  + character + '/angry/testing',\n","\t\t},\n","\t\t'sad': {\n","\t\t\t'training':'datasets/' + character + '/sad/training',\n","\t\t\t'testing':'datasets/'  + character + '/sad/testing',\n","\t\t}\n","\t}\n","\temotions_training = []\n","\temotions_testing = []\n","\n","\t# training\n","\t# append paths for happy training...\n","\tfor hd_train in os.listdir(DATASETS['happy']['training']):\n","\t\temotions_training.append(os.path.join(DATASETS['happy']['training'], hd_train))\n","\t\t\n","\t# append paths for angry training...\n","\tfor ad_train in os.listdir(DATASETS['angry']['training']):\n","\t\temotions_training.append(os.path.join(DATASETS['angry']['training'], ad_train))\n","\t\n","\t# Append paths for sad training...\n","\tfor sd_train in os.listdir(DATASETS['sad']['training']):\n","\t\temotions_training.append(os.path.join(DATASETS['sad']['training'], sd_train))\n","  \n","\t\n","\t# todo: append paths for other emotions for training...\n","\t# ...\n","\t\n","\t# testing\n","\t# append paths for happy testing...\n","\tfor hd_test in os.listdir(DATASETS['happy']['testing']):\n","\t\temotions_testing.append(os.path.join(DATASETS['happy']['testing'], hd_test))\n","\t\t\n","\t# append paths for angry testing...\n","\tfor ad_test in os.listdir(DATASETS['angry']['testing']):\n","\t\temotions_testing.append(os.path.join(DATASETS['angry']['testing'], ad_test))\n","\t\n","\t# append paths for surprise testing...\n","\tfor sd_test in os.listdir(DATASETS['sad']['testing']):\n","\t\temotions_testing.append(os.path.join(DATASETS['sad']['testing'], sd_test))\n","\t\t\n","\t# todo: append paths for other emotions for testing...\n","\t# ...\n","\t\n","\tdata_size = len(emotions_training) // len(DATASETS.keys())\n","\t\n","\t# labels\n","\t# happy labels / label 0\n","\thappy_labels_train = np.zeros(data_size)\n","\thappy_labels_test = np.zeros(data_size)\t\n","\t\n","\t# angry labels / label 1 (fill with ones)\n","\tangry_labels_train = np.zeros(data_size)\n","\tangry_labels_train.fill(1)\n","\tangry_labels_test = np.zeros(data_size)\n","\tangry_labels_test.fill(1)\n","\t\n","\t# sad labels / label 2 (fill with ones)\n","\tsad_labels_train = np.zeros(data_size)\n","\tsad_labels_train.fill(2)\n","\tsad_labels_test = np.zeros(data_size)\n","\tsad_labels_test.fill(2)\n"," \n"," # neutral labels / label 2 (fill with ones)\n","\tneutral_labels_train = np.zeros(data_size)\n","\tneutral_labels_train.fill(2)\n","\tneutral_labels_test = np.zeros(data_size)\n","\tneutral_labels_test.fill(2)\n","\t\n","\t# todo: other emotion labels / label n (fill with n's) (see the emotion array)\n","\t# ...\n","\t\n","\t# append training & testing emotion labels.\n","\temotion_training_labels = np.append(happy_labels_train, angry_labels_train)\n","\temotion_training_labels = np.append(emotion_training_labels, sad_labels_train)\n","\t\n","\temotion_testing_labels = np.append(happy_labels_test, angry_labels_test)\n","\temotion_testing_labels = np.append(emotion_testing_labels, sad_labels_test)\n","\t\n","\tprint (\"(training) loaded {} images & {} labels for {}...\").format(len(emotions_training), len(emotion_training_labels), character)\n","\tprint (\"(testing) loaded {} images & {} labels for {}...\").format(len(emotions_testing), len(emotion_testing_labels), character)\n","\t\n","\treturn (emotions_training, emotion_training_labels), (emotions_testing, emotion_testing_labels)\n","\n","# process images into numpy for training & testing.\n","def process_images(fp):\n","\timgs = []\n","\tfor f in fp:\n","\t\timg = load_img(f)\n","\t\timg = img.resize((w,h), Image.ANTIALIAS)\n","\t\timg = img_to_array(img) / 255\n","\t\timg = img.reshape(3, w, h)\n","\t\timgs.append(img)\n","\treturn np.array(imgs)\n","\n","# display an image with a or without a label in matplotlib.\n","def show_image(i, l=None):\n","\tplt.imshow(array_to_img(i[0].reshape(3, w, h)))\n","\tif l is not None:\n","\t\tprint (\"label: {}\").format(emotions[np.argmax(l[0])])\n","\tplt.axis('off')\n","\tplt.show()\n","\n","# fetches a random image from a given dataset.\n","# returns a numpy image, the original image and the ground truth label.\n","def random_image_from_dataset(i, gtl):\n","\tri = np.random.choice(len(i))\n","\tnumpy_img = i[ri]\n","\torig = array_to_img(numpy_img.reshape(3, w, h))\n","\tnumpy_img = i[ri].reshape(1, 3, w, h)\n","\treturn numpy_img, orig, gtl[ri]\n","\n","# configuration before classification and training.\n","def setup(reproduce=True):\n","\t# fix the seed to reproduce results in this dissertation.\n","\tseed = 12379231\n","\tif reproduce is True:\n","\t\tnp.random.seed(seed)\n","\tplt.rc('text', usetex=True)\n","\tplt.rc('font', family='serif')\n","\t\n","# callbacks for keras.\n","def load_callbacks():\n","\t# log to tensorboard for debugging and training + testing metrics.\n","\tif not os.path.exists('datasets/logs'):\n","\t\tos.mkdir('datasets/logs')\n","\tps = PlotStats()\n","\ttb = TensorBoard(log_dir='./datasets/logs', histogram_freq=1, write_graph=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n","\treturn [tb, ps]\n","\n","# main dataset loader for tom and jerry.\n","def load_dataset():\n","  angry_training, angry_testing = load_emotion_data_for(\"angry\")\n","  happy_training, happy_testing = load_emotion_data_for(\"happy\")\n","  \n","  training_i = np.append(angry_training[0], happy_training[0], sad_training[0])\n","  training_l = np.append(angry_training[1], happy_training[1], sad_training[1])\n","  \n","  testing_i = np.append(angry_testing[0], happy_testing[0], sad_training[0])\n","  training_l = np.append(angry_testing[1], happy_testing[1], sad_testing[1])\n","\t\n","  return (training_i, training_l), (testing_i, training_l)\n","\t\n","# perform training.\n","def load_training_and_testing_data():\n","\tprint (\"loading training & testing data...\")\n","\ttraining, testing = load_dataset()\n","\n","\t# process testing and training images -> numpy arrays.\n","\ttrain_images = process_images(training[0])\n","\ttest_images = process_images(testing[0])\n","\t\n","\t# convert training and testing to one hot vectors.\n","\ttrain_labels = one_hot(training[1], num_classes=6)\n","\ttest_labels = one_hot(testing[1], num_classes=6)\n","\t\n","\t# shuffle training data in sync for better training.\n","\trng = np.random.get_state()\n","\tnp.random.shuffle(train_images)\n","\tnp.random.set_state(rng)\n","\tnp.random.shuffle(train_labels)\n","\t\n","\t# partition dataset 80/20. (80 -> training, 20 -> testing)\n","\tr = np.random.rand(train_images.shape[0])\n","\tpart = r < np.percentile(r, 80)\n","\ttrain_images = train_images[part]\n","\ttrain_labels = train_labels[part]\n","\ttest_images = test_images[-part]\n","\ttest_labels = test_labels[-part]\n","\t\n","\t# optionally show images and labels.\n","\t# show_image(train_images, train_labels)\n","\t# show_image(test_images, test_labels)\n","\treturn train_images, train_labels, test_images, test_labels\n","\n","# train images and test labels.\n","def train(train_i, train_l, test_i, test_l, visualise, summary):\n","\t# additional callbacks to aid training and viewing plots and visualisations.\n","\tcb = load_callbacks()\n","\t\n","\t# load our cnn model.\n","\tcnn = load_cnn_model()\n","\t\n","\t# begin training and save the model when finished.\n","\tif not os.path.isfile('model_{}_.h5'.format(model_version)):\n","\t\tprint (\"training...\")\n","\t\tcnn.fit(train_i, train_l, epochs=epochs, batch_size=32, verbose=1, callbacks=cb, validation_data=(test_i, test_l))\n","\t\t# after training, save the weights.\n","\t\tcnn.save_weights('model_{}_.h5'.format(model_version))\n","\t\n","\t# load the weights if they exist.\n","\tcnn.load_weights('model_{}_.h5'.format(model_version))\n","\t\n","\t# model evaluation. \n","\tloss, acc = cnn.evaluate(test_i, test_l, verbose=0)\n","\tprint (\"model loss {:.1f}%\").format(loss)\n","\tprint (\"model accuracy {:.1f}%\\n\").format(acc)\n","\t\n","\t# print summary if true.\n","\tif summary is True:\n","\t\tprint (\"summary:\")\n","\t\tcnn.summary()\n","\t\n","\tif visualise is True:\n","\t\t# show at least n test results for testing.\n","\t\tn = 10\n","\t\tfor e, i in enumerate(range(n)):\n","\t\t\t# fetch a random image.\n","\t\t\ti, original, gtl = random_image_from_dataset(test_i, test_l)\n","\t\t\tplt.imshow(original)\n","\t\t\tplt.axis('off')\n","\t\t\t\n","\t\t\tprint (\"sample image: {}\\n---\").format(e+1)\n","\t\t\t\n","\t\t\t# get the predicted class and the predicted probabilities.\n","\t\t\tpred_class, prob = (cnn.predict_classes(i, verbose=0)[0], cnn.predict(i, verbose=0).flatten())\n","\t\t\tpredicted_emotion = str(emotions[pred_class])\n","\t\t\tground_truth_emotion = str(emotions[np.argmax(gtl)])\n","\t\t\tconfidence_score = float(prob[pred_class] * 100)\n","\t\t\t\n","\t\t\t# check if the label match the prediction.\n","\t\t\tif ground_truth_emotion is predicted_emotion:\n","\t\t\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"lime\")\n","\t\t\t\tprint (\"image prediction: {} | confidence score: ({:.1f}%)\").format(COLOR['G'] + predicted_emotion + COLOR['RS'], confidence_score)\n","\t\t\telse:\n","\t\t\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"red\")\n","\t\t\t\tprint (\"image prediction: {} | confidence score: ({:.1f}%)\").format(COLOR['R'] + predicted_emotion + COLOR['RS'], confidence_score)\t\n","\t\t\t\t\n","\t\t\t# display the closer emotion probabilities.\n","\t\t\tfor p in np.argsort(-prob):\n","\t\t\t\tprint (\"{}: {:.1f}%\").format(str(emotions[p]), float(prob[p] * 100))\n","\t\t\t\n","\t\t\t# display the ground truth emotion.\n","\t\t\tprint (\"ground truth: {}\\n\").format(COLOR['G'] + str(ground_truth_emotion) + COLOR['RS'])\n","\t\t\tplt.show()\n","\t\t\tplt.gcf().clf()\n","\t\t\t\n","# the main convolutional neural network architecture.\n","def load_cnn_model():\n","\t# define convnet model.\n","\tcnn = Sequential()\n","\t\n","\t# 3x3 convolution & 2x2 maxpooling with a input image of 60x60x3.\n","\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(3, w, h), name=\"conv_layer_1\"))\n","\tcnn.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_1'))\n","\n","\t# 3x3 convolution & 2x2 maxpooling.\n","\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_layer_2'))\n","\tcnn.add(MaxPooling2D(pool_size=(2, 2), name='maxpool_2'))\n","\n","\t# 3x3 convolution & 9x9 maxpooling.\n","\tcnn.add(Conv2D(32, (3, 3), activation='relu', padding='same', name='conv_layer_3'))\n","\tcnn.add(MaxPooling2D(pool_size=(9, 9), name='maxpool_3'))\n","\n","\t# dropout 50% and flatten layer.\n","\tcnn.add(Dropout(0.5))\n","\tcnn.add(Flatten(name='flatten_1'))\n","\t\n","\t# fully connected layers and the output layer.\n","\tcnn.add(Dense(512, activation='relu', name='fully_connected_1'))\n","\tcnn.add(Dense(6, activation='softmax', name='output_layer'))\n","\to = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","\tcnn.compile(loss='categorical_crossentropy', optimizer=o, metrics=['accuracy'])\n","\t\n","\t# return the cnn model.\n","\treturn cnn\n","\n","# classify an emotion from an image.\n","def classify_emotion_from_image(local_image):\n","\t# classify input image, if it exists.\n","\tif os.path.isfile('model_{}_.h5'.format(model_version)):\n","\t\tprint(\"loading model...\")\n","\t\tcnn = load_cnn_model()\n","\t\tcnn.load_weights('model_{}_.h5'.format(model_version))\n","\t\n","\t\t# load local image.\n","\t\tloaded_img = process_images(local_image)\n","\t\tprint(\"classifying...\")\n","\t\t\n","\t\t# get the predicted class and the predicted probabilities.\n","\t\tpred_class, prob = (cnn.predict_classes(loaded_img, verbose=0)[0], cnn.predict(loaded_img, verbose=0).flatten())\n","\t\tpredicted_emotion = str(emotions[pred_class])\n","\t\tconfidence_score = float(prob[pred_class] * 100)\n","\t\tprint(\"image: {}\\n---\").format(sys.argv[2])\n","\t\tprint(\"image prediction: {} | confidence score: ({:.1f}%)\").format(COLOR['G'] + predicted_emotion + COLOR['RS'], confidence_score)\n","\t\t\n","\t\t# display the closer emotion probabilities.\n","\t\tfor p in np.argsort(-prob):\n","\t\t\tprint (\"{}: {:.1f}%\").format(str(emotions[p]), float(prob[p] * 100))\n","\t\t\n","\t\t# display image.\n","\t\tplt.text(3, 7, predicted_emotion.title(), fontsize=36, color=\"purple\")\n","\t\tshow_image(loaded_img)\n","\telse:\n","\t\tprint (\"unable to classify image \\'{}\\', model does not exist, train the network first.\").format(local_image[0])\n","\n","# create visualisations, requires a predefined model.\n","def vis(img):\n","\tif os.path.isfile('model_{}_.h5'.format(model_version)):\n","\t\tprint ('loading model...')\n","\t\tcnn = load_cnn_model()\n","\t\tcnn.load_weights('model_{}_.h5'.format(model_version))\n","\t\t\n","\t\t# list all layers in loaded model.\n","\t\tlayer_name = \"output_layer\"\n","\t\tlayer_idx = [idx for idx, layer in enumerate(cnn.layers) if layer.name == layer_name][0]\n","\t\t\n","\t\t# selected layers to visualise.\n","\t\tlayers = ['conv_layer_1', 'conv_layer_2', 'conv_layer_3', 'output_layer']\n","\t\t\n","\t\t# visualise convnet visualisation for each layer, place them in a subplot.\n","\t\tfor layer_name in layers:\n","\t\t\tprint (\"Generating visualisation of {}\").format(layer_name)\n","\t\t\tlayer_idx = [idx for idx, layer in enumerate(cnn.layers) if layer.name == layer_name][0]\n","\t\t\t\n","\t\t\tif 'conv' not in layer_name:\t\n","\t\t\t\tplt.figure()\n","\t\t\t\tfor idx, e in enumerate(emotions):\n","\t\t\t\t\tplt.subplot(6, 6, idx + 1)\n","\t\t\t\t\tplt.text(1, 7, '{}'.format(e))\n","\t\t\t\t\timg = visualize_activation(cnn, layer_idx, filter_indices=idx, max_iter=750)\n","\t\t\t\t\timg = array_to_img(img.reshape(3, w, h))\n","\t\t\t\t\tplt.axis('off')\n","\t\t\t\t\tplt.imshow(img)\n","\t\t\t\t\n","\t\t\t\tplt.suptitle('Visualisation of the Output Layer')\n","\t\t\t\tplt.savefig('{}.png'.format(layer_name), bbox_inches='tight')\n","\t\t\t\tplt.show()\n","\t\t\t\tbreak\n","\t\t\t\n","\t\t\tfilters = np.arange(get_num_filters(cnn.layers[layer_idx]))\n","\t\t\t\n","\t\t\timages = []\n","\t\t\tfor idx in filters:\n","\t\t\t\timg = visualize_activation(cnn, layer_idx, tv_weight=0, verbose=False, filter_indices=idx, max_iter=750)\n","\t\t\t\timg = array_to_img(img.reshape(3, w, h))\n","\t\t\t\timages.append(img)\n","\t\t\t\n","\t\t\tplt.figure()\n","\t\t\tfor idx, i in enumerate(images):\n","\t\t\t\tplt.subplots_adjust(wspace=0, hspace=0)\n","\t\t\t\tplt.subplot(6, 6, idx + 1)\n","\t\t\t\tplt.text(0, 15, 'Filter {}'.format(idx) )\n","\t\t\t\tplt.axis('off')\n","\t\t\t\tplt.imshow(i)\n","\t\t\t\t\n","\t\t\tplt.suptitle('Visualisation of Convolution Layer {}'.format(layer_name[len(layer_name)-1]))\n","\t\t\tplt.savefig('{}.png'.format(layer_name), bbox_inches='tight')\n","\t\t\tplt.show()\n","\t\t\t\n","\telse:\n","\t\tprint ('model does not exist, train the network first.')\n","\t\t\n","def main():\n","\tvisualise_classification = False\n","\tsummary = False\n","\t\n","\t# -V - visualise convnet layers.\n","\tif '-V' in sys.argv[1:]:\n","\t\tvis(sys.argv[2:])\n","\t\t\n","\t# -t - train or visualise classification or print a summary of the model.\n","\telif '-t' in sys.argv[1:]:\n","\t\ttrain_i, train_l, test_i, test_l = load_training_and_testing_data()\n","\t\tif '-v' in sys.argv[1:]:\n","\t\t\tvisualise_classification = True\n","\t\tif '-s' in sys.argv[1:]:\n","\t\t\tsummary = True\n","\t\ttrain(train_i, train_l, test_i, test_l, visualise_classification, summary)\n","\t\n","\t\n","\t# -c - classify, classifies one image from an existing model.\n","\telif '-c' in sys.argv[1:]:\n","\t\tif os.path.isfile(sys.argv[2]):\n","\t\t\t# load image for classification.\n","\t\t\tloaded_img = [sys.argv[2]]\n","\t\t\tclassify_emotion_from_image(loaded_img)\n","\t\t\n","\t\telse:\n","\t\t\tprint ('unable to classify image \\'{}\\', does not exist.').format(sys.argv[2])\n","\t\n","\t\n","\telse:\n","\t\tprint ('### Deep Learning for Emotion Recognition in Cartoons ###')\n","\t\tprint ('training: (and show summary or results)')\n","\t\tprint ('usage: train.py -t [-v|-s]\\n')\n","\t\tprint ('classification:')\n","\t\tprint ('usage: train.py -c image.jpg')\n","\t\tprint ('visualisation:')\n","\t\tprint ('usage: train.py -V')\n","\t\t\n","if __name__ == '__main__':\n","\t# early setup\n","\tsetup(False)\n","\tK.image_data_format()\n","\tmain()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBCD9L-F-f4x","executionInfo":{"status":"ok","timestamp":1679631879099,"user_tz":-330,"elapsed":417,"user":{"displayName":"Soutrik Roy","userId":"15339520230730619614"}},"outputId":"1463060b-1b92-438b-ca61-308a42ba9f46"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["### Deep Learning for Emotion Recognition in Cartoons ###\n","training: (and show summary or results)\n","usage: train.py -t [-v|-s]\n","\n","classification:\n","usage: train.py -c image.jpg\n","visualisation:\n","usage: train.py -V\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wPuwITNlC8xF","executionInfo":{"status":"ok","timestamp":1679584791932,"user_tz":-330,"elapsed":5,"user":{"displayName":"Soutrik Roy","userId":"15339520230730619614"}}},"execution_count":25,"outputs":[]}]}